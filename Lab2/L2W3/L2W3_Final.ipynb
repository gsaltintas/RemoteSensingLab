{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDrVgozAyd-Q"
   },
   "source": [
    "# Pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13918,
     "status": "ok",
     "timestamp": 1651743160244,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "YAIPu8EMyggi",
    "outputId": "770de0ac-e198-432a-ab1f-c44b0de2cfc4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! pip install pytorch_lightning;\n",
    "# ! pip install wandb;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1651743161472,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "I_yfwZxq9HMb",
    "outputId": "f63dcbbb-dbfa-4bb4-c8d5-0e4a1d873da8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgsaltintas\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.12.11'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "wandb.login()\n",
    "wandb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1683,
     "status": "ok",
     "timestamp": 1651743164195,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "GR7a9D24xxBe",
    "outputId": "9a7b0c55-8bac-406d-999b-3b023260dfb9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8b1b6e56f08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "# Rodrigo Caye Daudt\n",
    "# rodrigo.cayedaudt@geod.baug.ethz.ch\n",
    "# 04/2021\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "from EuroSAT_dataset import EuroSAT\n",
    "from network import Net\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "if not os.path.exists('./outputs'):\n",
    "    os.mkdir('./outputs')\n",
    "\n",
    "print('Imports OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAmraZtX6uBC"
   },
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1651743238923,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "GWz1fTMnxxBn",
    "outputId": "75ac6115-98e7-44d9-90cb-52bd28245f82"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0a2aded08f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# If USE_CUDA is True, computations will be done using the GPU (may not work in all systems)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This will make the calculations happen faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mUSE_CUDA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mDATASET_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../EuroSAT_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Global parameters\n",
    "\n",
    "# If USE_CUDA is True, computations will be done using the GPU (may not work in all systems)\n",
    "# This will make the calculations happen faster\n",
    "USE_CUDA = torch.cuda.is_available() \n",
    "\n",
    "DATASET_PATH = '../EuroSAT_data'\n",
    "\n",
    "BATCH_SIZE = 32 # Number of images that are used for calculating gradients at each step\n",
    "\n",
    "NUM_EPOCHS = 20 # Number of times we will go through all the training images. Do not go over 25\n",
    "\n",
    "LEARNING_RATE = 1e-3 # Controls the step size\n",
    "MOMENTUM = 0.9 # 0.0 # Momentum for the gradient descent\n",
    "WEIGHT_DECAY = 1e-6 # Regularization factor to reduce overfitting\n",
    "\n",
    "\n",
    "grading = False\n",
    "print('Parameters OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1651743168106,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "WTuPhZKoxxBp",
    "outputId": "0d945d6e-28e0-4dcc-e55a-b65ef1c99e5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsa/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EuroSAT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-391e333b9f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Create datasets and data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuroSAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EuroSAT' is not defined"
     ]
    }
   ],
   "source": [
    "from torch._C import device\n",
    "# Create datasets and data loaders\n",
    "train_dataset = EuroSAT(DATASET_PATH, True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = EuroSAT(DATASET_PATH, False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "print('Dataloaders OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfHx3hWLAFdY"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1651743168110,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "vvsXPYO6xxBr"
   },
   "outputs": [],
   "source": [
    "# Criterion, optimizer, and scheduler\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() # Do not change this\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4536,
     "status": "ok",
     "timestamp": 1651743225052,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "227PaLKAxxBr",
    "outputId": "9685c39c-d878-4952-a6ac-8f96e0dbbaa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n",
      "Network OK\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', device)\n",
    "\n",
    "# Create network\n",
    "net = Net(loss_func=criterion, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "if USE_CUDA:\n",
    "    net = net.cuda()\n",
    "\n",
    "print('Network OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3cL8979isk7",
    "outputId": "3b8e5bed-37fc-48c2-93d4-941dfe3b278e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.device, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 5279,
     "status": "ok",
     "timestamp": 1651743232008,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "yqjmobxIxxBs",
    "outputId": "0e6d92b6-4782-4120-9a51-9cc51c7b9edc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Define pytorchlightning parameters\n",
    "grading = True\n",
    "if not grading: \n",
    "    wandb_logger = WandbLogger(entity=os.environ['WANDB_ENTITY'],\n",
    "                           project='remote_sensing',\n",
    "                           log_model=True\n",
    "                           )\n",
    "    wandb_logger.watch(net)\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=2,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "    trainer_params = {'callbacks': [checkpoint_callback, lr_monitor], \n",
    "                    'max_epochs': NUM_EPOCHS,\n",
    "                      'auto_lr_find': True,\n",
    "                      'logger': wandb_logger,\n",
    "                      'log_every_n_steps': 5\n",
    "                     }\n",
    "else:\n",
    "    trainer_params = {'max_epochs': NUM_EPOCHS,\n",
    "                      'auto_lr_find': True,\n",
    "                      'logger': False,\n",
    "                     }\n",
    "if USE_CUDA:\n",
    "    trainer_params['gpus'] = [0]\n",
    "    \n",
    "trainer = pl.Trainer(**trainer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "aborted",
     "timestamp": 1651743168975,
     "user": {
      "displayName": "GUL SENA ALTINTAS",
      "userId": "12401586871728145313"
     },
     "user_tz": -120
    },
    "id": "KV0wbnPyxxBu"
   },
   "outputs": [],
   "source": [
    "trainer.fit(net, train_loader, test_loader,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDfBc3ZviebX"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "L41clOLbxxBx"
   },
   "outputs": [],
   "source": [
    "# Helper function to organize main loop\n",
    "# This function is called for training and for testing at each epoch\n",
    "\n",
    "def run_epoch(net, optimizer, dataloader, criterion, train=True, cuda=USE_CUDA):\n",
    "    epoch_total_loss = 0\n",
    "    epoch_total_samples = 0\n",
    "    epoch_total_correct = 0\n",
    "\n",
    "    for sample in tqdm(dataloader):\n",
    "        img = sample['image']\n",
    "        label = sample['label']\n",
    "\n",
    "        if cuda:\n",
    "            img, label = img.cuda(), label.cuda()\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "        out = net(img)\n",
    "        loss = criterion(out, label)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            epoch_total_samples += img.size(0)\n",
    "            epoch_total_loss += img.size(0) * loss\n",
    "            epoch_total_correct += torch.sum(torch.argmax(out, dim=1) == label)\n",
    "\n",
    "    return epoch_total_loss / epoch_total_samples, epoch_total_correct / epoch_total_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2V9NgcshxxB0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 169/169 [00:25<00:00,  6.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(2.3687), tensor(0.0919))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "loss, accuracy = run_epoch(net, None, test_loader, criterion, False)\n",
    "print(f'Final test loss: {loss}')\n",
    "print(f'Final test accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WDrVgozAyd-Q",
    "UZtoSYxjymmE"
   ],
   "name": "L2W3-Copy1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
